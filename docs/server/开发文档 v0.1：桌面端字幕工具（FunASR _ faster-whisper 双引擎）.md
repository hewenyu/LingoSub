<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" class="logo" width="120"/>

# 开发文档 v0.1：桌面端字幕工具（FunASR / faster-whisper 双引擎）

**核心结论**

1. FunASR 与 faster-whisper 都能输出时间戳级别的转写结果；FunASR 在中文场景自带断句、标点与 ITN，faster-whisper 速度更快、模型选择更灵活。
2. 建议的工作流：`音频 → ASR → 粗字幕 → Netflix 规范化 → GUI 校对/导出`。
3. 桌面端可采用 PySide6 (Qt) 实现跨平台 GUI，并通过统一的“引擎适配层”切换识别后端。

## 一、整体架构

```
┌────────────┐      ┌──────────┐       ┌───────────────┐
│  音频文件  │ ───► │  引擎层  │ ───►  │  粗字幕(SRT)  │
└────────────┘      │• FunASR │       └──────┬────────┘
                    │• faster │              │
                    └──────────┘              ▼
                                      ┌──────────────────┐
                                      │ Netflix 规范化器 │
                                      └──────┬───────────┘
                                             ▼
                                       精修字幕 (SRT/TTML)
```


## 二、引擎适配层

### 2.1 FunASR

特点

- Paraformer-large、SenseVoice 等工业级模型，中文 CER≈1.9%[^1]。
- 自带 VAD、标点、热词、ITN，可一次性完成“听写+修饰”[^2][^3]。
- 支持 `onnx / libtorch / TensorRT` 部署。

最小示例

```python
from funasr import AutoModel
model = AutoModel(model="paraformer-zh",
                  vad_model="fsmn-vad",
                  punc_model="ct-punc",
                  device="cuda:0")
res = model.generate(input="demo.wav",
                     merge_vad=True, use_itn=True)
# res[^0] = {'text': '...', 'timestamp': [[beg,end],...]}
```

关键参数


| 参数 | 说明 |
| :-- | :-- |
| `merge_vad` | 将 VAD 片段重新合并，减少断句 |
| `batch_size_s` | 动态批次，提升 GPU 利用率 |
| `fa_model` / `timestamp` | 若需逐字时间戳，可调用 `fa-zh` 模型[^4] |

### 2.2 faster-whisper

特点

- CTranslate2 推理，最高可比原生 Whisper 提速 4×[^5]。
- 支持 fp16 / int8 量化、批量推理。
- 自动语言检测，输出分段及（可选）逐词时间戳。

最小示例

```python
from faster_whisper import WhisperModel
model = WhisperModel("large-v3", device="cuda", compute_type="int8_float16")
segments, _ = model.transcribe("demo.wav",
                               beam_size=5,
                               word_timestamps=True)
for s in segments:
    print(s.start, s.end, s.text)
```

性能提示


| 参数 | 影响 | 建议 |
| :-- | :-- | :-- |
| `model_size` | 速度 / 准确率 | 中文建议 `medium` 以上 |
| `batch_size` | GPU 吞吐 | 取决于显存，8–16 常见[^5] |
| `word_timestamps` | 精确定位 | 后期做 Netflix 拆行需开启 |

## 三、粗字幕生成

### 3.1 时间轴拼接

1. **FunASR** 直接返回句级时间戳数组。
2. **faster-whisper** 按段返回；如需句级，可根据中文/英文标点重新 split 并线性插值时间。
```python
def segments_to_srt(segments, path):
    with open(path,'w',encoding='utf8') as f:
        for i,s in enumerate(segments,1):
            f.write(f"{i}\n")
            f.write(to_srt_time(s.start)+' --> '+to_srt_time(s.end)+'\n')
            f.write(s.text.strip()+'\n\n')
```


### 3.2 初版 SRT 输出

建议在“引擎层”结束后立即落盘 `draft.srt`，供用户复查。

## 四、Netflix 规范化器

Netflix 《Timed-Text Style Guide》核心规则（英/中）


| 维度 | 关键点 |
| :-- | :-- |
| 字符数 | 英文 ≤ 42 cpl[^6]；简体/繁体中文 ≤ 16[^7][^8] |
| 行数 | ≤ 2 行，每行尽量完整语义[^9] |
| 显示时长 | 0.5 s – 7 s，推荐成人 ≤ 20 CPS[^6] |
| 标点 | 用 U+2026 单字符省略号，破折号表示打断[^6] |
| 多说话人 | 行首 `–` 区分，同段至多两人[^6] |
| 音乐/音效 | `[♪ 歌词]`、`[门关上]` 方括号 |

### 4.1 自动修正流程

```
粗字幕 → 断句 + 拆行 + 限长 + 补语义 → Netflix 合规字幕
```

伪代码

```python
def polish_sub(srt_in, srt_out, lang='zh'):
    max_len = 16 if lang=='zh' else 42
    new_items = []
    for item in parse_srt(srt_in):
        lines = smart_wrap(item.text, max_len)
        # 计算 cps，必要时缩短或切分 event
        duration = item.end - item.start
        cps = len(''.join(lines)) / duration
        if cps > 20:
            lines = compress_text(lines)
        item.text = '\n'.join(lines)
        new_items.append(item)
    write_srt(new_items, srt_out)
```

工具库

- `pysubs2`：解析/写入 SRT/ASS。
- `nle`（Netflix Language Engineering）社区脚本：自动检测字符数、时长。


### 4.2 多人说话/音效标记

- FunASR 可加 **Speaker Diarization** 流水线 `paraformer-vad-spk`，生成 `spk_id`。
- faster-whisper 暂无自带分离，可结合 `pyannote.audio` 先做说话人分段。
- 后处理时为新段前加 `–` 并对齐时间轴。


## 五、桌面 GUI 实现

### 5.1 技术选型

| 方案 | 语言 | 优势 | 劣势 |
| :-- | :-- | :-- | :-- |
| PySide6 (Qt for Python) | Python | 与本地 ASR 代码同栈；Qt Designer 可视化开发 | 打包体积偏大 |
| Electron / Tauri | JS/Rust 前端 | UI 友好；Tauri 体积小 | 与 Python 引擎需 IPC |
| .NET MAUI | C\# | 跨平台统一 | 与 Python 需绑定层 |

**推荐**：PySide6 + `asyncio` 线程池调用引擎；`QMediaPlayer` 预览视频 + 可编辑字幕表格。

### 5.2 模块划分

```
gui/
 ├─ engine/            # 引擎适配层 (funasr.py, whisper.py)
 ├─ processor/         # Netflix 规范化器
 ├─ widgets/
 │   ├─ timeline.py    # 波形+字幕轨
 │   └─ subtitle_table.py
 ├─ main.py
 └─ resources.qrc
```

GUI 关键交互

1. 导入音/视频 → 选择引擎 → “识别”按钮（后台线程）。
2. 粗字幕展示，可人工改行、改词。
3. “规范化”按钮自动执行 Netflix 规则，提示超限行（红色高亮）。
4. 导出：SRT / TTML / ASS。

## 六、质量评估与测试

| 指标 | 方法 |
| :-- | :-- |
| WER / CER | 参考集 + `jiwer` / `nfcorpus-eval` |
| 时间轴误差 | 字级对齐后统计 Δt |
| Netflix 合规率 | 运行脚本检查超过字符/时长的条目数 |
| UI 体验 | 10 人 Beta 使用问卷 |

## 七、后续迭代路线

1. **模型热更新**：提供 UI 选项直接下载/切换模型（FunASR ModelScope、Whisper HF）。
2. **批量处理**：支持文件夹/拖拽队列，自动轮询 GPU 占用。
3. **脚本插件**：开放 Python Hook（如术语替换、机器翻译）。
4. **TTAL 导出**：兼容 Netflix Timed-Text Authoring Lineage 生态[^10]。

## 附：主要参考

FunASR 论文与特性概述[^1]；官方 SDK 部署文档[^3]；PyPI 说明[^2]。
faster-whisper 基准与使用说明[^5]；速度/特性综述[^11][^12]。
Netflix 英文、中文时长与排版规范[^6][^7][^9].

<div style="text-align: center">⁂</div>

[^1]: https://www.isca-archive.org/interspeech_2023/gao23g_interspeech.pdf

[^2]: https://pypi.org/project/funasr/

[^3]: https://developer.aliyun.com/ask/588337

[^4]: https://huggingface.co/funasr/fa-zh

[^5]: https://partnerhelp.netflixstudios.com/hc/en-us/articles/217350977-English-USA-Timed-Text-Style-Guide

[^6]: https://www.scribd.com/document/581609848/manual-da-netflix

[^7]: https://partnerhelp.netflixstudios.com/hc/en-us/articles/215994807-Chinese-Traditional-Timed-Text-Style-Guide

[^8]: https://netflixtechblog.com/introducing-netflix-timed-text-authoring-lineage-6fb57b72ad41

[^9]: https://accessiblelibraries.ca/resources/netflix-english-timed-text-style-guide/

[^10]: https://arxiv.org/abs/2305.11013

[^11]: https://mysoly.nl/speech-to-text-with-faster-whisper-the-high-speed-alternative-to-openai-whisper/

[^12]: https://openai.com/index/whisper/

[^13]: https://github.com/modelscope/FunASR

[^14]: https://github.com/SYSTRAN/faster-whisper

[^15]: https://github.com/alibaba-damo-academy/FunASR/blob/main/runtime/docs/SDK_tutorial.md

[^16]: https://pypi.org/project/funasr/0.7.9/

[^17]: https://huggingface.co/funasr/fsmn-vad

[^18]: https://aiola.ai/the-tech-talk/medusa-architect/

[^19]: https://www.deepchecks.com/llm-tools/faster-whisper/

[^20]: https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.parsers.audio.FasterWhisperParser.html

[^21]: https://github.com/joshuaboniface/remote-faster-whisper

[^22]: https://docs.pruna.ai/en/v0.1.3/tutorials_nb/asr_whisper.html

[^23]: https://www.scribd.com/document/533492155/Netflix-Timed-Text-Guide

[^24]: https://partnerhelp.netflixstudios.com/hc/en-us/articles/215986007-Chinese-Simplified-Timed-Text-Style-Guide

[^25]: https://partnerhelp.netflixstudios.com/hc/en-us/articles/215758617-Timed-Text-Style-Guide-General-Requirements

[^26]: https://cnb.cool/vytron/funasr/-/blob/main/runtime/docs/SDK_advanced_guide_offline.md

[^27]: https://fireworks.ai/blog/audio-transcription-launch

[^28]: https://www.reddit.com/r/LocalLLaMA/comments/1d1j31r/faster_whisper_server_an_openai_compatible_server/

[^29]: https://www.youtube.com/watch?v=UoElgXzBIqE

[^30]: https://www.infoq.com/news/2025/07/jakarta-ee-11-updates/

